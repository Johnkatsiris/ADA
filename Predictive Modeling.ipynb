{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898a3aad-efd6-4ed7-9730-c0ed571a12d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "accb8084-f537-42c6-98f1-77fd829b5a31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "def load_data(data):\n",
    "    return pd.read_csv(data.csv)\n",
    "\n",
    "# Remove duplicate rows\n",
    "def remove_duplicates(df):\n",
    "    return df.drop_duplicates()\n",
    "\n",
    "# Handle missing data\n",
    "def handle_missing_data(df, method='drop', fill_value=None):\n",
    "    if method == 'drop':\n",
    "        return df.dropna()\n",
    "    elif method == 'fill':\n",
    "        return df.fillna(fill_value)\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "# Correct data types\n",
    "def correct_data_types(df, column_type_dict):\n",
    "    for column, dtype in column_type_dict.items():\n",
    "        df[column] = df[column].astype(dtype)\n",
    "    return df\n",
    "\n",
    "# Filter irrelevant data\n",
    "def filter_data(df, columns_to_keep):\n",
    "    return df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f5f9bd7-5f9b-425a-8bf5-c728d218528d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_data(df, columns_to_keep):\n",
    "    return df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bda3856-582e-4904-a945-7d21e9e10540",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Row ID;Order ID;Order Date;Ship Date;Ship Mode;Customer ID;Customer Name;Segment;Country;City;State;Postal Code;Region;Product ID;Category;Sub-Category;Product Name;Cost;Price;Profit;Quantity;Sales\\n',\n",
       " '1;CA-2017-152156;8/11/17;11/11/17;Second Class;CG-12520;Claire Gute;Consumer;United States;Henderson;Kentucky;42420;South;FUR-BO-10001798;Furniture;Bookcases;Bush Somerset Collection Bookcase;464.48;901.06;436.58;4;3.604.243.977\\n',\n",
       " '2;CA-2017-152156;8/11/17;11/11/17;Second Class;CG-12520;Claire Gute;Consumer;United States;Henderson;Kentucky;42420;South;FUR-CH-10000454;Furniture;Chairs;Hon Deluxe Fabric Upholstered Stacking Chairs, Rounded Back;756.10;138.70;-617.40;12;1.664.369.269\\n',\n",
       " '3;CA-2017-138688;12/6/17;16/6/17;Second Class;DV-13045;Darrin Van Huff;Corporate;United States;Los Angeles;California;90036;West;OFF-LA-10000240;Office Supplies;Labels;Self-Adhesive Address Labels for Typewriters by Universal;537.68;159.28;-378.40;12;191.139.775\\n',\n",
       " \"4;US-2016-108966;11/10/16;18/10/16;Standard Class;SO-20335;Sean O'Donnell;Consumer;United States;Fort Lauderdale;Florida;33311;South;FUR-TA-10000577;Furniture;Tables;Bretford CR4500 Series Slim Rectangular Table;875.91;445.88;-430.03;13;5.796.463.018\\n\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's read the first few lines of the file to identify the delimiter and the general structure\n",
    "with open('data.csv', 'r') as file:\n",
    "    first_lines = [next(file) for _ in range(5)]\n",
    "\n",
    "first_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67e3f342-d696-4a17-8318-6e53e8e57150",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best Parameters: {'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None, 'max_depth': 10, 'criterion': 'entropy'}\n",
      "Best Cross-Validation Score: 0.9075941289087428\n",
      "Decision Tree Accuracy: 0.9198570699336396\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.89      0.92      1008\n",
      "        True       0.89      0.95      0.92       951\n",
      "\n",
      "    accuracy                           0.92      1959\n",
      "   macro avg       0.92      0.92      0.92      1959\n",
      "weighted avg       0.92      0.92      0.92      1959\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('data.csv', delimiter=';')\n",
    "\n",
    "# Convert date columns to datetime format\n",
    "data['Order Date'] = pd.to_datetime(data['Order Date'], format='%d/%m/%y')\n",
    "data['Ship Date'] = pd.to_datetime(data['Ship Date'], format='%d/%m/%y')\n",
    "\n",
    "# Handle missing values in 'Postal Code' column by filling with the most frequent value\n",
    "data['Postal Code'].fillna(data['Postal Code'].mode()[0], inplace=True)\n",
    "\n",
    "# Convert 'Sales' column to numeric format\n",
    "data['Sales'] = data['Sales'].str.replace('.', '').astype(float)\n",
    "\n",
    "# Encode categorical variables using one-hot encoding\n",
    "data_encoded = pd.get_dummies(data, columns=[\n",
    "    'Ship Mode', 'Segment', 'Country', 'City', 'State', 'Region', \n",
    "    'Category', 'Sub-Category'\n",
    "])\n",
    "\n",
    "# Convert date columns to timestamps\n",
    "data_encoded['Order Date'] = pd.to_numeric(data_encoded['Order Date'])\n",
    "data_encoded['Ship Date'] = pd.to_numeric(data_encoded['Ship Date'])\n",
    "\n",
    "# Select features and target\n",
    "features = data_encoded.drop(columns=['Quantity', 'Profit', 'Order ID', 'Customer ID', 'Customer Name', 'Product ID', 'Product Name'])\n",
    "target_quantity = data_encoded['Quantity'] > data_encoded['Quantity'].median()  # Binary classification: above median\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target_quantity, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter grid for Randomized Search\n",
    "param_dist = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30, 40],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': [None, 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV with cross-validation\n",
    "random_search = RandomizedSearchCV(estimator=DecisionTreeClassifier(), param_distributions=param_dist, \n",
    "                                   n_iter=50, cv=5, n_jobs=-1, verbose=2, random_state=42)\n",
    "\n",
    "# Fit RandomizedSearchCV to the data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params_random = random_search.best_params_\n",
    "best_score_random = random_search.best_score_\n",
    "\n",
    "# Train the Decision Tree model with the best parameters\n",
    "best_decision_tree_model = DecisionTreeClassifier(**best_params_random)\n",
    "best_decision_tree_model.fit(X_train, y_train)\n",
    "decision_tree_preds = best_decision_tree_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "decision_tree_accuracy = accuracy_score(y_test, decision_tree_preds)\n",
    "decision_tree_report = classification_report(y_test, decision_tree_preds)\n",
    "\n",
    "print(f\"Best Parameters: {best_params_random}\")\n",
    "print(f\"Best Cross-Validation Score: {best_score_random}\")\n",
    "print(f\"Decision Tree Accuracy: {decision_tree_accuracy}\")\n",
    "print(f\"Classification Report:\\n{decision_tree_report}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21c753c7-e9ed-41bb-97a4-c582a971b354",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9851965288412455\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.99      0.99      1008\n",
      "        True       0.99      0.98      0.98       951\n",
      "\n",
      "    accuracy                           0.99      1959\n",
      "   macro avg       0.99      0.99      0.99      1959\n",
      "weighted avg       0.99      0.99      0.99      1959\n",
      "\n",
      "Linear Regression Mean Squared Error: 2169617738918666.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('data.csv', delimiter=';')\n",
    "\n",
    "# Convert date columns to datetime format\n",
    "data['Order Date'] = pd.to_datetime(data['Order Date'], format='%d/%m/%y')\n",
    "data['Ship Date'] = pd.to_datetime(data['Ship Date'], format='%d/%m/%y')\n",
    "\n",
    "# Handle missing values in 'Postal Code' column by filling with the most frequent value\n",
    "data['Postal Code'].fillna(data['Postal Code'].mode()[0], inplace=True)\n",
    "\n",
    "# Convert 'Sales' column to numeric format\n",
    "data['Sales'] = data['Sales'].str.replace('.', '').astype(float)\n",
    "\n",
    "# Encode categorical variables using one-hot encoding\n",
    "data_encoded = pd.get_dummies(data, columns=[\n",
    "    'Ship Mode', 'Segment', 'Country', 'City', 'State', 'Region', \n",
    "    'Category', 'Sub-Category'\n",
    "])\n",
    "\n",
    "# Convert date columns to timestamps\n",
    "data_encoded['Order Date'] = pd.to_numeric(data_encoded['Order Date'])\n",
    "data_encoded['Ship Date'] = pd.to_numeric(data_encoded['Ship Date'])\n",
    "\n",
    "# Select features and target\n",
    "features = data_encoded.drop(columns=['Order ID', 'Customer ID', 'Customer Name', 'Product ID', 'Product Name'])\n",
    "target_quantity = data_encoded['Quantity'] > data_encoded['Quantity'].median()  # Binary classification: above median\n",
    "target_sales = data_encoded['Sales']  # Regression: predicting sales\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train_class, y_test_class = train_test_split(features, target_quantity, test_size=0.2, random_state=42)\n",
    "_, _, y_train_reg, y_test_reg = train_test_split(features, target_sales, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "logistic_model.fit(X_train_scaled, y_train_class)\n",
    "logistic_preds = logistic_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the Logistic Regression model\n",
    "logistic_accuracy = accuracy_score(y_test_class, logistic_preds)\n",
    "logistic_report = classification_report(y_test_class, logistic_preds)\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {logistic_accuracy}\")\n",
    "print(f\"Classification Report:\\n{logistic_report}\")\n",
    "\n",
    "# Train the Linear Regression model\n",
    "linear_reg_model = LinearRegression()\n",
    "linear_reg_model.fit(X_train_scaled, y_train_reg)\n",
    "linear_reg_preds = linear_reg_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the Linear Regression model\n",
    "regression_mse = mean_squared_error(y_test_reg, linear_reg_preds)\n",
    "\n",
    "print(f\"Linear Regression Mean Squared Error: {regression_mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a4d592a-e704-4df7-a483-07b65f0fbb76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9851965288412455\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.99      0.99      1008\n",
      "        True       0.99      0.98      0.98       951\n",
      "\n",
      "    accuracy                           0.99      1959\n",
      "   macro avg       0.99      0.99      0.99      1959\n",
      "weighted avg       0.99      0.99      0.99      1959\n",
      "\n",
      "Linear Regression Mean Squared Error: 2169617738918666.0\n",
      "Decision Tree Regressor Mean Squared Error: 9150833420702.795\n",
      "Random Forest Regressor Mean Squared Error: 2330352269850.9434\n",
      "Gradient Boosting Regressor Mean Squared Error: 350185049956428.9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('data.csv', delimiter=';')\n",
    "\n",
    "# Convert date columns to datetime format\n",
    "data['Order Date'] = pd.to_datetime(data['Order Date'], format='%d/%m/%y')\n",
    "data['Ship Date'] = pd.to_datetime(data['Ship Date'], format='%d/%m/%y')\n",
    "\n",
    "# Handle missing values in 'Postal Code' column by filling with the most frequent value\n",
    "data['Postal Code'].fillna(data['Postal Code'].mode()[0], inplace=True)\n",
    "\n",
    "# Convert 'Sales' column to numeric format\n",
    "data['Sales'] = data['Sales'].str.replace('.', '').astype(float)\n",
    "\n",
    "# Encode categorical variables using one-hot encoding\n",
    "data_encoded = pd.get_dummies(data, columns=[\n",
    "    'Ship Mode', 'Segment', 'Country', 'City', 'State', 'Region', \n",
    "    'Category', 'Sub-Category'\n",
    "])\n",
    "\n",
    "# Convert date columns to timestamps\n",
    "data_encoded['Order Date'] = pd.to_numeric(data_encoded['Order Date'])\n",
    "data_encoded['Ship Date'] = pd.to_numeric(data_encoded['Ship Date'])\n",
    "\n",
    "# Select features and target\n",
    "features = data_encoded.drop(columns=['Order ID', 'Customer ID', 'Customer Name', 'Product ID', 'Product Name'])\n",
    "target_quantity = data_encoded['Quantity'] > data_encoded['Quantity'].median()  # Binary classification: above median\n",
    "target_sales = data_encoded['Sales']  # Regression: predicting sales\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train_class, y_test_class = train_test_split(features, target_quantity, test_size=0.2, random_state=42)\n",
    "_, _, y_train_reg, y_test_reg = train_test_split(features, target_sales, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "logistic_model.fit(X_train_scaled, y_train_class)\n",
    "logistic_preds = logistic_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the Logistic Regression model\n",
    "logistic_accuracy = accuracy_score(y_test_class, logistic_preds)\n",
    "logistic_report = classification_report(y_test_class, logistic_preds)\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {logistic_accuracy}\")\n",
    "print(f\"Classification Report:\\n{logistic_report}\")\n",
    "\n",
    "# Train and evaluate Linear Regression model\n",
    "linear_reg_model = LinearRegression()\n",
    "linear_reg_model.fit(X_train_scaled, y_train_reg)\n",
    "linear_reg_preds = linear_reg_model.predict(X_test_scaled)\n",
    "linear_reg_mse = mean_squared_error(y_test_reg, linear_reg_preds)\n",
    "print(f\"Linear Regression Mean Squared Error: {linear_reg_mse}\")\n",
    "\n",
    "# Train and evaluate Decision Tree Regressor\n",
    "tree_reg_model = DecisionTreeRegressor()\n",
    "tree_reg_model.fit(X_train_scaled, y_train_reg)\n",
    "tree_reg_preds = tree_reg_model.predict(X_test_scaled)\n",
    "tree_reg_mse = mean_squared_error(y_test_reg, tree_reg_preds)\n",
    "print(f\"Decision Tree Regressor Mean Squared Error: {tree_reg_mse}\")\n",
    "\n",
    "# Train and evaluate Random Forest Regressor\n",
    "forest_reg_model = RandomForestRegressor(n_estimators=100)\n",
    "forest_reg_model.fit(X_train_scaled, y_train_reg)\n",
    "forest_reg_preds = forest_reg_model.predict(X_test_scaled)\n",
    "forest_reg_mse = mean_squared_error(y_test_reg, forest_reg_preds)\n",
    "print(f\"Random Forest Regressor Mean Squared Error: {forest_reg_mse}\")\n",
    "\n",
    "# Train and evaluate Gradient Boosting Regressor\n",
    "gb_reg_model = GradientBoostingRegressor(n_estimators=100)\n",
    "gb_reg_model.fit(X_train_scaled, y_train_reg)\n",
    "gb_reg_preds = gb_reg_model.predict(X_test_scaled)\n",
    "gb_reg_mse = mean_squared_error(y_test_reg, gb_reg_preds)\n",
    "print(f\"Gradient Boosting Regressor Mean Squared Error: {gb_reg_mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0935eb6-3b53-4b54-8ce4-8a9da378d326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
